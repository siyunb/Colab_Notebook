{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wang.ipynb","provenance":[],"authorship_tag":"ABX9TyOWy5TOmPGfre1Z3C9b7I7l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSQ1V12km_ni","cellView":"form","executionInfo":{"status":"ok","timestamp":1616606492606,"user_tz":-540,"elapsed":16660,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}},"outputId":"295fd97d-25b1-4c27-b3a9-ff02f3631593"},"source":["#@title Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xavn8twJq8n","executionInfo":{"status":"ok","timestamp":1616606494331,"user_tz":-540,"elapsed":523,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}},"outputId":"bbe2d597-b4f9-4f48-c23b-5750fd40cc1a"},"source":["cd gdrive/MyDrive/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vVTP2obRQYZ9","executionInfo":{"status":"ok","timestamp":1616655721054,"user_tz":-540,"elapsed":4696,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}}},"source":["import  torch\n","import  torch.nn as nn\n","import  torch.nn.functional as F\n","import  torch.optim as optim\n","from  torchvision import datasets, transforms\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbnejKL-SXHl","executionInfo":{"status":"ok","timestamp":1616655721054,"user_tz":-540,"elapsed":2711,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}}},"source":["t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n","t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n","t_c = torch.tensor(t_c)\n","t_u = torch.tensor(t_u)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJCI10fas9fW","executionInfo":{"status":"ok","timestamp":1616655722565,"user_tz":-540,"elapsed":1068,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}}},"source":["def model(t_u, w, b):\n","  return w*t_u + b\n","\n","def loss_fn(t_p, t_c):\n","  squared_diffs = (t_p - t_c)**2\n","  return squared_diffs.mean()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwtbaHhPQNU-","executionInfo":{"status":"ok","timestamp":1616655724722,"user_tz":-540,"elapsed":1355,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}}},"source":["params = torch.tensor([1.0, 0.0], requires_grad = True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"obF0F8ZeQ1Ml","executionInfo":{"status":"ok","timestamp":1616656506341,"user_tz":-540,"elapsed":1229,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}}},"source":["def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n","  for epoch in range(1, n_epochs + 1):\n","    if params.grad is not None:\n","      params.grad.zero_()\n","    t_p = model(t_u, *params)\n","    loss = loss_fn(t_p, t_c)\n","    loss.backward()\n","    params = (params - learning_rate*params.grad).detach().requires_grad_()\n","    if epoch%500 == 0:\n","      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n","  return params\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnM8nXy5NO7G","executionInfo":{"status":"ok","timestamp":1616656509360,"user_tz":-540,"elapsed":830,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}}},"source":["params = torch.tensor([1.0, 0.0], requires_grad=True)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbej0LS5UJxV","executionInfo":{"status":"ok","timestamp":1616656547904,"user_tz":-540,"elapsed":2080,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}},"outputId":"e6c37cab-578f-4167-b100-878d094a5c21"},"source":["training_loop(5000, 1e-2, params, 0.1*t_u, t_c)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch 500, Loss 7.860115\n","Epoch 1000, Loss 3.828538\n","Epoch 1500, Loss 3.092191\n","Epoch 2000, Loss 2.957698\n","Epoch 2500, Loss 2.933134\n","Epoch 3000, Loss 2.928648\n","Epoch 3500, Loss 2.927830\n","Epoch 4000, Loss 2.927679\n","Epoch 4500, Loss 2.927652\n","Epoch 5000, Loss 2.927647\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([  5.3671, -17.3012], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"T67HiANvIz7Q"},"source":["import  torch\n","import  torch.nn as nn\n","import  torch.nn.functional as F\n","import  torch.optim as optim\n","from  torchvision import datasets, transforms\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision\n","\n","\n","batch_size=200\n","learning_rate=0.01\n","epochs=10\n","\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data', train=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])), batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])), batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KuRf3-cscxVf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616410526145,"user_tz":-540,"elapsed":84928,"user":{"displayName":"王思雨","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdKvMq1fEVrSVYMjY_lkMRC-UmX30N77KQ_6cd=s64","userId":"09556943149130240731"}},"outputId":"cc2a1822-6fca-4f8f-878e-54b8fe1c27c9"},"source":["class MLP(nn.Module):\n","\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(784, 200),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Linear(200, 200),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Linear(200, 10),\n","            nn.LeakyReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","\n","        return x\n","\n","device = torch.device('cuda:0')  #初始化GPU\n","net = MLP().to(device)       #初始化类并将其全连接类分配到GPU\n","optimizer = optim.SGD(net.parameters(), lr=learning_rate) #初始化优化器分配参数\n","criteon = nn.CrossEntropyLoss().to(device)    # 初始化损失函数并分配给GPU\n","\n","for epoch in range(epochs):\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data = data.view(-1, 28*28)\n","        data, target = data.to(device), target.cuda()  #初始化数据并分配给gpu\n","\n","        logits = net(data)\n","        loss = criteon(logits, target)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # print(w1.grad.norm(), w2.grad.norm())\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                       100. * batch_idx / len(train_loader), loss.item()))\n","\n","\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        data = data.view(-1, 28 * 28)\n","        data, target = data.to(device), target.cuda()\n","        logits = net(data)\n","        test_loss += criteon(logits, target).item()\n","\n","        pred = logits.data.max(1)[1]\n","        correct += pred.eq(target.data).sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.305637\n","Train Epoch: 0 [20000/60000 (33%)]\tLoss: 2.010831\n","Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.401249\n","\n","Test set: Average loss: 0.0047, Accuracy: 7754/10000 (78%)\n","\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.006127\n","Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.887509\n","Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.798570\n","\n","Test set: Average loss: 0.0032, Accuracy: 8120/10000 (81%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.643918\n","Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.496492\n","Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.367412\n","\n","Test set: Average loss: 0.0018, Accuracy: 8991/10000 (90%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.383935\n","Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.324373\n","Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.331903\n","\n","Test set: Average loss: 0.0016, Accuracy: 9064/10000 (91%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.365042\n","Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.333837\n","Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.254854\n","\n","Test set: Average loss: 0.0015, Accuracy: 9137/10000 (91%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.296687\n","Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.324164\n","Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.377917\n","\n","Test set: Average loss: 0.0014, Accuracy: 9208/10000 (92%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.240948\n","Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.310385\n","Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.249668\n","\n","Test set: Average loss: 0.0013, Accuracy: 9245/10000 (92%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.384655\n","Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.269575\n","Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.315733\n","\n","Test set: Average loss: 0.0012, Accuracy: 9276/10000 (93%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.244770\n","Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.294430\n","Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.287698\n","\n","Test set: Average loss: 0.0012, Accuracy: 9324/10000 (93%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.212781\n","Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.290575\n","Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.258266\n","\n","Test set: Average loss: 0.0011, Accuracy: 9351/10000 (94%)\n","\n"],"name":"stdout"}]}]}