{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "pharmaceutical-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "legendary-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0] #known data\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] #unknown data\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "serial-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alpine-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None: \n",
    "            params.grad.zero_() # 这可以在调用backward之前在循环中的任何时候完成\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "        params = (params - learning_rate * params.grad).detach().requires_grad_()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "instructional-patrick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860115\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957698\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_un = 0.1 * t_u\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-2,\n",
    "    params = torch.tensor([1.0, 0.0], requires_grad=True),\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "allied-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "medieval-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0965, -0.0165], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "incoming-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    optimizer = optim.SGD([params], lr = learning_rate)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None: \n",
    "            params.grad.zero_() # 这可以在调用backward之前在循环中的任何时候完成\n",
    "        loss = loss_fn(model(t_u, *params), t_c)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "conceptual-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = loss_fn(model(t_u, *params), t_c)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "reported-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "stuck-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860115\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957698\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_un = 0.1 * t_u\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "blessed-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "equipped-house",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.612900\n",
      "Epoch 1000, Loss 3.086700\n",
      "Epoch 1500, Loss 2.928579\n",
      "Epoch 2000, Loss 2.927644\n",
      "Epoch 2500, Loss 2.927645\n",
      "Epoch 3000, Loss 2.927646\n",
      "Epoch 3500, Loss 2.927645\n",
      "Epoch 4000, Loss 2.927646\n",
      "Epoch 4500, Loss 2.927646\n",
      "Epoch 5000, Loss 2.927645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.5368, -17.3048], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_u,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "regulation-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "obvious-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 5, 3, 1, 2, 8, 7, 0, 9]), tensor([10,  4]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2*n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "blessed-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices] \n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "train_t_un = train_t_u*0.1\n",
    "val_t_un = val_t_u*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "thirty-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch %d, Training Loss %.2f, Validation Loss %.2f' % (epoch, train_loss.float(), val_loss.float()))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "acquired-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "surgical-pasta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Training Loss 32.35, Validation Loss 14.88\n",
      "Epoch 100, Training Loss 26.35, Validation Loss 11.49\n",
      "Epoch 150, Training Loss 19.50, Validation Loss 9.84\n",
      "Epoch 200, Training Loss 13.95, Validation Loss 8.28\n",
      "Epoch 250, Training Loss 9.78, Validation Loss 6.98\n",
      "Epoch 300, Training Loss 6.88, Validation Loss 5.92\n",
      "Epoch 350, Training Loss 5.00, Validation Loss 5.08\n",
      "Epoch 400, Training Loss 3.88, Validation Loss 4.44\n",
      "Epoch 450, Training Loss 3.27, Validation Loss 3.96\n",
      "Epoch 500, Training Loss 2.99, Validation Loss 3.60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.1335, -15.9296], requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=500, optimizer = optimizer, params = params, \n",
    "              train_t_u = train_t_u, train_t_c = train_t_c, val_t_u = val_t_u, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "exciting-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_t_p = model(val_t_u, *params)\n",
    "            val_loss = loss_fn(val_t_p, val_t_c)\n",
    "            assert val_loss.requires_grad == False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch %d, Training Loss %.2f, Validation Loss %.2f' % (epoch, train_loss.float(), val_loss.float()))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "systematic-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "stupid-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Training Loss 27.32, Validation Loss 17.74\n",
      "Epoch 100, Training Loss 17.60, Validation Loss 12.63\n",
      "Epoch 150, Training Loss 10.88, Validation Loss 9.16\n",
      "Epoch 200, Training Loss 6.83, Validation Loss 6.84\n",
      "Epoch 250, Training Loss 4.66, Validation Loss 5.36\n",
      "Epoch 300, Training Loss 3.61, Validation Loss 4.46\n",
      "Epoch 350, Training Loss 3.15, Validation Loss 3.92\n",
      "Epoch 400, Training Loss 2.97, Validation Loss 3.61\n",
      "Epoch 450, Training Loss 2.90, Validation Loss 3.43\n",
      "Epoch 500, Training Loss 2.88, Validation Loss 3.34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.2488, -16.6556], requires_grad=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=500, optimizer = optimizer, params = params, \n",
    "              train_t_u = train_t_u, train_t_c = train_t_c, \n",
    "              val_t_u = val_t_u, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "played-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    t_p = w_2*t_u*t_u + w_1*t_u + b\n",
    "    return t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "satellite-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clalc_forward(t_u, t_c, params,is_train):\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "brutal-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = clalc_forward(train_t_u, train_t_c, params, is_train = True)\n",
    "        val_loss = clalc_forward(val_t_u, val_t_c, params, is_train = False)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch %d, Training Loss %.2f, Validation Loss %.2f' % (epoch, train_loss.float(), val_loss.float()))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "alleged-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "extra-sewing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Training Loss 7.06, Validation Loss 6.64\n",
      "Epoch 100, Training Loss 4.39, Validation Loss 3.14\n",
      "Epoch 150, Training Loss 3.49, Validation Loss 2.44\n",
      "Epoch 200, Training Loss 3.25, Validation Loss 2.10\n",
      "Epoch 250, Training Loss 3.18, Validation Loss 1.96\n",
      "Epoch 300, Training Loss 3.14, Validation Loss 1.91\n",
      "Epoch 350, Training Loss 3.10, Validation Loss 1.90\n",
      "Epoch 400, Training Loss 3.06, Validation Loss 1.89\n",
      "Epoch 450, Training Loss 3.01, Validation Loss 1.89\n",
      "Epoch 500, Training Loss 2.97, Validation Loss 1.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5050, -0.0422, -4.1968], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=500, optimizer = optimizer, params = params, \n",
    "              train_t_u = train_t_u, train_t_c = train_t_c, \n",
    "              val_t_u = val_t_u, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "impressive-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0] #known data\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] #unknown data\n",
    "t_c = torch.tensor(t_c).unsqueeze(1)\n",
    "t_u = torch.tensor(t_u).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "italic-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(1,1)\n",
    "optimizer = optim.SGD(linear_model.parameters(),lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-gathering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
