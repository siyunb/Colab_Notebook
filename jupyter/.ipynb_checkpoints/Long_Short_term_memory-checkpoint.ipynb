{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turkish-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, device):\n",
    "    norm = torch.tensor([0.0], device = device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data**2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta/norm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comprehensive-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr*param.grad/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifth-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x,n_class):\n",
    "    x = x.long()\n",
    "    res=torch.zeros(x.shape[0],n_class, dtype = torch.float, device = x.device)\n",
    "    res.scatter_(1,x.view(-1,1),1)\n",
    "    return res\n",
    "def to_onehot(X, n_class):\n",
    "    return [one_hot(X[:,i],n_class) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "representative-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_jay_lyrics():\n",
    "    with zipfile.ZipFile('./Dataset/JayLyrics/jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n',' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx_dict = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    idx_to_char_dict = dict([(i, char) for i, char in enumerate(idx_to_char)])\n",
    "    corpus_indice = [char_to_idx_dict[char] for char in corpus_chars]\n",
    "    return corpus_chars, corpus_indice, idx_to_char_dict, char_to_idx_dict, len(idx_to_char_dict)\n",
    "\n",
    "corpus_chars, corpus_indice, idx_to_char_dict, char_to_idx_dict, vocab_size = load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lucky-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indice, batch_size, num_step, device):\n",
    "    corpus_indice = torch.tensor(corpus_indice, dtype = torch.float, device = device)\n",
    "    data_len = len(corpus_indice)\n",
    "    batch_len = data_len//batch_size\n",
    "    indice = corpus_indice[0:batch_len*batch_size].view(batch_size, batch_len)\n",
    "    epoch_size = batch_len//num_step\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        i = i*num_step\n",
    "        X = indice[:, i: i+num_step]\n",
    "        Y = indice[:, i+1:i+num_step+1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacterial-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size = shape), device = device, dtype = torch.float)\n",
    "        return  nn.Parameter(ts, requires_grad = True)\n",
    "    \n",
    "    def _three():\n",
    "        return (_one((num_inputs, num_hiddens)),\n",
    "                _one((num_hiddens, num_hiddens)),\n",
    "                nn.Parameter(torch.zeros(num_hiddens, device = device, dtype = torch.float, requires_grad = True)))\n",
    "    \n",
    "    W_xf, W_hf, b_f = _three()            #parameters of forget gate\n",
    "    W_xi, W_hi, b_i = _three()            #parameters of input gate\n",
    "    W_xc, W_hc, b_c = _three()            #parameters of candidate gate\n",
    "    W_xo, W_ho, b_o = _three()            #parameters of output gate\n",
    "    \n",
    "    #输出层参数\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = nn.Parameter(torch.zeros(num_outputs, device = device, dtype = torch.float), requires_grad=True)\n",
    "    \n",
    "    return nn.ParameterList([W_xf, W_hf, b_f, W_xi, W_hi, b_i, W_xc, W_hc, b_c, W_xo, W_ho, b_o, W_hq, b_q])\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recovered-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lstm_state(batch_size, num_hiddens):\n",
    "    C = torch.zeros((batch_size, num_hiddens), dtype = torch.float, device = device)       #C initial matrix\n",
    "    H = torch.zeros((batch_size, num_hiddens), dtype = torch.float, device = device)       #H initial matrix\n",
    "    return (C, H)\n",
    "\n",
    "def lstm(inputs, init_state, params):\n",
    "    W_xf, W_hf, b_f, W_xi, W_hi, b_i, W_xc, W_hc, b_c, W_xo, W_ho, b_o, W_hq, b_q = params\n",
    "    C, H = init_state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        F = torch.sigmoid(torch.mm(X, W_xf)+torch.mm(H, W_hf)+b_f)\n",
    "        I = torch.sigmoid(torch.mm(X, W_xi)+torch.mm(H, W_hi)+b_i)\n",
    "        O = torch.sigmoid(torch.mm(X, W_xo)+torch.mm(H, W_ho)+b_o)\n",
    "        C_tilda = torch.tanh(torch.mm(X, W_xc)+torch.mm(H, W_hc)+b_c)\n",
    "        C = F*C + I*C_tilda\n",
    "        H = O*torch.tanh(C) \n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (C, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "underlying-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lstm(prefix, num_chars, init_state_fn, model, params, idx_to_char_dict, char_to_idx_dict):\n",
    "    W_xf, W_hf, b_f, W_xi, W_hi, b_i, W_xc, W_hc, b_c, W_xo, W_ho, b_o, W_hq, b_q = params\n",
    "    vocab_size = len(idx_to_char_dict)\n",
    "    output = [prefix[0]]\n",
    "    test_state = init_state_fn(len(output), W_hf.shape[1]) \n",
    "    \n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X_indice = torch.tensor([char_to_idx_dict[output[-1]]], device = device).view(-1,1)\n",
    "        X_one_hot = to_onehot(X_indice, vocab_size)\n",
    "        Y, test_state = model(X_one_hot, test_state, params)\n",
    "        if t<len(prefix)-1: \n",
    "            output.append(prefix[t+1])\n",
    "        else:    \n",
    "            output.append(idx_to_char_dict[int(Y[0].argmax(dim = 1).item())])\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "architectural-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(corpus_indice, data_iter, batch_size, num_steps, num_hiddens, num_epoches,\n",
    "                      device, init_state_fn, model, lr, clipping_theta, params,\n",
    "                      idx_to_char_dict, char_to_idx_dict, \n",
    "                      prefixes, num_chars):\n",
    "    \n",
    "    vocab_size = len(idx_to_char_dict)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epoches): \n",
    "        train_loss_sum, n = 0.0, 0\n",
    "        train_state = init_state_fn(batch_size, num_hiddens)\n",
    "        for X_indice_list, Y_indice_list in data_iter(corpus_indice, batch_size, num_steps, device):\n",
    "            train_state = (train_state[0].detach(), train_state[1].detach())\n",
    "            X_one_hot = to_onehot(X_indice_list, vocab_size)\n",
    "            Y_hat_one_hot, train_state = lstm(X_one_hot, train_state, params)\n",
    "            outputs = torch.cat(Y_hat_one_hot, dim=0)\n",
    "            Y_indice_list = torch.transpose(Y_indice_list, 0, 1).contiguous().view(-1).long()\n",
    "            loss = loss_fn(outputs, Y_indice_list)\n",
    "            \n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            grad_clipping(params, clipping_theta, device)\n",
    "            sgd(params, lr, 1)\n",
    "            train_loss_sum += loss.item()\n",
    "            n += 1\n",
    "            \n",
    "        if (epoch+1)%50 == 0:\n",
    "            train_loss = train_loss_sum/n\n",
    "            try:\n",
    "                perplexity = math.exp(train_loss)\n",
    "            except OverflowError:\n",
    "                perplexity = float('inf')\n",
    "            print('epoch: %d, train_loss: %.2f, perplexity: %f'%(epoch+1, train_loss, perplexity))\n",
    "            \n",
    "            for prefix in prefixes:\n",
    "                print(predict_lstm(prefix, num_chars, init_state_fn, model, params, idx_to_char_dict, char_to_idx_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ignored-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches, num_steps, batch_size, lr, clipping_theta = 300, 50, 32, 1e3, 1e-2\n",
    "num_chars, prefixes = 50, ['分开','不分开']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "accessory-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, train_loss: 3.24, perplexity: 25.495932\n",
      "分开  我  我   我 我      我 我   我 我 我 我 我 我 我 我 我 我 我 我 我 \n",
      "不分开暴你说  我      我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 \n",
      "epoch: 100, train_loss: 2.33, perplexity: 10.245249\n",
      "分开始的手不  我的外  我想  我想你的我的可爱你的可不  爱情  我想 我想你的看远    我   \n",
      "不分开  我不能  我想 我不能 我想要 我想你的黑白 看 一个 我爱女  我想想 我想   我想你 我也\n",
      "epoch: 150, train_loss: 1.66, perplexity: 5.256422\n",
      "分开始的让我 一个许在那已经过  是我后能不是一定实很久了汉堡 在抽离开的我的 的 一切又 一个满  我\n",
      "不分开暴风 我不想想了很美走 就怎么我跟透不会金 一步三步望著我 一枝步两  相爱我可爱女人  你爱我不能\n",
      "epoch: 200, train_loss: 1.43, perplexity: 4.169124\n",
      "分开始共山  在那里 不达米的快就耳 哼哼哼哈兮 飞 飞 如果我 在最  你  你 太彻   没有你是让\n",
      "不分开暴  不舍 爱你 你 太快就这样 难过去 不放开不 后出的 对不能知后 哼哼哈兮 它在抽离  爱  \n",
      "epoch: 250, train_loss: 1.09, perplexity: 2.987868\n",
      "分开始共多 难过了 一颗三颗   你 你的完 是  的回忆  对不 后  我胸  你 你   你 你 太\n",
      "不分开     你 你    你 你 太快就能活  这样 印地安的在 爱我  爱你 你    你 你 太快\n",
      "epoch: 300, train_loss: 1.04, perplexity: 2.824185\n",
      "分开始 一只看远  我 我的手 我胸起  我 我 我的手 我的手 我胸定 我的手不能知不会痛  我 我 \n",
      "不分开暴 我 我不想  我的手不觉  我不能了离  我 我 我 我的手 我的手 我胸定 我的手不能知不会痛\n",
      "epoch: 350, train_loss: 0.93, perplexity: 2.530883\n",
      "分开始共  我 我的脑袋 什么  我爱你 你  我的手的话  我爱情了口  我不能  我不 我不能  我\n",
      "不分开暴力  我的 我给你的完美索不 后出  静静的在想要  我的手的那已无处后还真是谁是国依旧每天都没有\n",
      "epoch: 400, train_loss: 0.93, perplexity: 2.524052\n",
      "分开始共一步望著天的溪边河片段 一枝杨柳的在西元前世纪后说法是谁的雨 在西元前 双截棍棒走 你爱写在我连\n",
      "不分开暴力向开不要你和汉堡里一起线背著我马儿一起个满了它一颗四颗两步四三步望就怎么每天都难熬好生活 有伤害\n",
      "epoch: 450, train_loss: 0.89, perplexity: 2.438400\n",
      "分开始共三点阳光射进教堂的黑白色幽默的牛肉 泪被我一定一颗三颗四三颗心到 看星 我的脑袋瓜有轻的让我面的\n",
      "不分开暴不了雕我的脑袋有轻的让我一切记 它所以后到我想要你想要你已无能知后悔着你看到大自在吸吐箭 我的脑的\n",
      "epoch: 500, train_loss: 0.85, perplexity: 2.340857\n",
      "分开始共渡每天每日折一九四颗四颗两步望著天 我想多地安跳什么我不想通 有伤害 我不能够一直走 我的手不好\n",
      "不分开 我不想要你已无能承受我不想要你已无能承受我不多的黑色幽默默的爹娘子我不想就像是你只能看你已无能承受\n",
      "epoch: 550, train_loss: 0.81, perplexity: 2.255500\n",
      "分开始共渡每天在那年代落 在美索不觉 不多难过气 不觉 我不想很美老了口默默的在美索不觉 不多难过气 不\n",
      "不分开暴力 别离开始共三点阳光 不想要再想要你来和汉 不要再想要你的愿望就像是我的太彻底格里你 在这样的心\n",
      "epoch: 600, train_loss: 0.80, perplexity: 2.222065\n",
      "分开始共三点阳光 干嘛怎么都能拿你 我不能知后再想就能看欢我有多年代种里 我想多说散 有别发我想一直的星\n",
      "不分开暴力 它在人的你的完美索不想  我不能承受我不想很美主 在哭泣 我胸定会念咒 我的脑袋担心伤哼哈兮 \n",
      "epoch: 650, train_loss: 0.82, perplexity: 2.259580\n",
      "分开 我 我想多 我想多 却依旧时光 一些著背著我马我 我想想要你 我的脑袋 说法典 一枝著天 一只能看\n",
      "不分开  我的手  我爱情来到我的手不了这里很久 我 我的手不可见  我的手  我爱情来到我的手不会离开 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d1a8a091c18d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_and_predict(corpus_indice, data_iter_consecutive, batch_size, num_steps, num_hiddens, num_epoches,\n\u001b[0m\u001b[0;32m      2\u001b[0m                       \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_lstm_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclipping_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                       \u001b[0midx_to_char_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_to_idx_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                       prefixes, num_chars)\n",
      "\u001b[1;32m<ipython-input-37-5e3f7d5cebe6>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[1;34m(corpus_indice, data_iter, batch_size, num_steps, num_hiddens, num_epoches, device, init_state_fn, model, lr, clipping_theta, params, idx_to_char_dict, char_to_idx_dict, prefixes, num_chars)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtrain_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mX_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_onehot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_indice_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mY_hat_one_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_one_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_hat_one_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mY_indice_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_indice_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-fcc2c6b51471>\u001b[0m in \u001b[0;36mlstm\u001b[1;34m(inputs, init_state, params)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mF_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_xf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_t_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mI_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_xi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_t_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mO_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_xo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_t_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_ho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb_o\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mC_t_tilda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_xc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_t_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mC_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF_t\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mC_t_1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mI_t\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mC_t_tilda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_predict(corpus_indice, data_iter_consecutive, batch_size, num_steps, num_hiddens, num_epoches,\n",
    "                      device, init_lstm_state, lstm, lr, clipping_theta, params,\n",
    "                      idx_to_char_dict, char_to_idx_dict, \n",
    "                      prefixes, num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-experiment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-crown",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-blake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-plastic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
