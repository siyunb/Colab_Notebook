{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equal-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "from torch.nn import init\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescribed-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize = None, path = './Dataset/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(transforms.Resize(size = resize))\n",
    "    trans.append(transforms.ToTensor())\n",
    "    transform = transforms.Compose(trans)\n",
    "    \n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root = path, train = True, download = True, transform = transform) \n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root = path,  train = False, download = True, transform = transform)\n",
    "    \n",
    "    train_iter = DataLoader(mnist_train, batch_size= batch_size, shuffle = True, num_workers = 4) \n",
    "    test_iter = DataLoader(mnist_test, batch_size = batch_size, shuffle = True, num_workers = 4)\n",
    "    \n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southeast-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, network, device = None):\n",
    "    if device is None:\n",
    "        device = list(network.parameters())[0].device\n",
    "    with torch.no_grad():\n",
    "        acc_num, n = 0.0, 0 \n",
    "        for X_test, y_test in data_iter:\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            network.eval()\n",
    "            y_hat = network(X_test)\n",
    "            acc_num  += (y_hat.argmax(dim = 1)==y_test.to(device)).sum().cpu().item()\n",
    "            network.train()\n",
    "            n += y_test.shape[0]\n",
    "    acc = acc_num/n\n",
    "    return acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brown-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, network, device = None):\n",
    "    if device is None:\n",
    "        device = list(network.parameters())[0].device\n",
    "    with torch.no_grad():\n",
    "        acc_num, n = 0.0, 0 \n",
    "        for X_test, y_test in data_iter:\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            network.eval()\n",
    "            y_hat = network(X_test)\n",
    "            acc_num  += (y_hat.argmax(dim = 1)==y_test.to(device)).sum().cpu().item()\n",
    "            network.train()\n",
    "            n += y_test.shape[0]\n",
    "    acc = acc_num/n\n",
    "    return acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controlling-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, train_iter, test_iter, optimizer, num_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "    network = network.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs): \n",
    "        train_loss_sum, train_acc_num, batch_count, n, start_time = 0.0, 0, 0, 0, time.time() \n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = network(X)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum += loss.cpu().item()\n",
    "            train_acc_num += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, network)\n",
    "        print('epoch: %d, train_loss: %.3f, train_acc: %.3f, test_acc: %.3f, time: %.2f'\n",
    "              %(epoch+1, train_loss_sum/batch_count, train_acc_num/n, test_acc, (time.time()-start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "southwest-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_1_1conv=False, stride=1):\n",
    "        super().__init__()\n",
    "        #justify the set of parameter rational\n",
    "        if (in_channels!=out_channels) or (stride!=1): \n",
    "            assert use_1_1conv == True, 'must adjust the shape of original matrix, please let the use_1_1conv be True'\n",
    "        if in_channels == out_channels:\n",
    "            assert use_1_1conv == False, 'if in_channels == out_channels, use_1_1conv must be False'\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1) #padding必为1保持与conv3的长宽同步\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)               #第二层必不减少长和宽\n",
    "        if use_1_1conv:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)        #stride与conv1同步，保持长宽同步\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.ac = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = self.ac(self.bn1(self.conv1(X)))\n",
    "        Y = self.conv2(Y)\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X) \n",
    "        return self.ac(self.bn2(Y + X))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "trying-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,X):\n",
    "        return X.mean(dim = 2, keepdim = True).mean(dim = 3, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hispanic-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(in_channels, out_channels, num_res, first_block = False):\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels, 'the in_channel and out_channels must be same in the first block' \n",
    "    blk = []\n",
    "    for i in range(num_res):\n",
    "        if (i == 0) and (not first_block): \n",
    "            blk.append(Residual(in_channels, out_channels, use_1_1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upset-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_block = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "                       )\n",
    "\n",
    "fc_block = nn.Sequential(GlobalAvgPool2d(),\n",
    "                  nn.Flatten(),\n",
    "                  nn.Linear(512, 10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "statewide-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "Res_Net = nn.Sequential()\n",
    "Res_Net.add_module('conv_block', conv_block)\n",
    "Res_Net.add_module('resnet_block1', res_block(64, 64, 2, first_block=True))\n",
    "Res_Net.add_module('resnet_block2', res_block(64, 128, 2))\n",
    "Res_Net.add_module('resnet_block3', res_block(128, 256, 2))\n",
    "Res_Net.add_module('resnet_block4', res_block(256, 512, 2))\n",
    "Res_Net.add_module('fc_block', fc_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "periodic-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_block outshape: torch.Size([1, 64, 56, 56])\n",
      "resnet_block1 outshape: torch.Size([1, 64, 56, 56])\n",
      "resnet_block2 outshape: torch.Size([1, 128, 28, 28])\n",
      "resnet_block3 outshape: torch.Size([1, 256, 14, 14])\n",
      "resnet_block4 outshape: torch.Size([1, 512, 7, 7])\n",
      "fc_block outshape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1,1,224,224)\n",
    "for name, layer in Res_Net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, 'outshape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "young-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bibliographic-seafood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_loss: 0.395, train_acc: 0.855, test_acc: 0.844, time: 14.70\n",
      "epoch: 2, train_loss: 0.281, train_acc: 0.897, test_acc: 0.889, time: 13.71\n",
      "epoch: 3, train_loss: 0.239, train_acc: 0.912, test_acc: 0.885, time: 13.72\n",
      "epoch: 4, train_loss: 0.212, train_acc: 0.921, test_acc: 0.899, time: 13.79\n",
      "epoch: 5, train_loss: 0.188, train_acc: 0.930, test_acc: 0.902, time: 13.88\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = optim.Adam(Res_Net.parameters(), lr = lr)\n",
    "train_network(Res_Net, train_iter, test_iter, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-notification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-mattress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-funeral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-education",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-brook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-victim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-nowhere",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-journalist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-filling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-badge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-leisure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-showcase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-photographer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-strengthening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-poster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-audience",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-royalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-employee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-wedding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-ocean",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
