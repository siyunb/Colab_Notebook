{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data \n",
    "from torch.nn import init\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import time \n",
    "import sys\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images_list, labels_list):\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    _, figs_list = plt.subplots(1, len(images_list), figsize = (12, 12))\n",
    "    for fig, image, label in zip(figs_list, images_list, labels_list):\n",
    "        fig.imshow(image.view(28, 28).numpy())\n",
    "        fig.set_title(label)\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_fashion_mnist_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-920a90a31921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mimages_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlabels_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mshow_fashion_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_fashion_mnist_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_fashion_mnist_labels' is not defined"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST(root = './Dataset/FashionMNIST', train = True, \n",
    "                                                    download = True, transform = transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root = './Dataset/FashionMNIST', train = False, \n",
    "                                                   download = True, transform = transforms.ToTensor())\n",
    "images_list, labels_list = [], []\n",
    "for i in range(10):\n",
    "    images_list.append(mnist_train[i][0])\n",
    "    labels_list.append(mnist_train[i][1])\n",
    "show_fashion_mnist(images_list, get_fashion_mnist_labels(labels_list))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据切割\n",
    "def load_data_fashion_mnist(batch_size):\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root = './Dataset/FashionMNIST', train = True, \n",
    "                                                    download = True, transform = transforms.ToTensor())\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root = './Dataset/FashionMNIST', train = False, \n",
    "                                                   download = True, transform = transforms.ToTensor())\n",
    "    if sys.platform.startswith('win'):\n",
    "        num_workers = 4\n",
    "    else:\n",
    "        num_workers = 0\n",
    "    train_iter = Data.DataLoader(mnist_train, batch_size = batch_size, shuffle = True, num_workers = num_workers)\n",
    "    test_iter = Data.DataLoader(mnist_test, batch_size = batch_size, shuffle = True, num_workers = num_workers)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参数初始化\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype = torch.float, requires_grad = True)\n",
    "b = torch.zeros(num_outputs, dtype = torch.float, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax 函数\n",
    "def softmax_fn(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(dim = 1, keepdim = True)\n",
    "    return X_exp/partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss 函数\n",
    "def cross_entropy(y_hat, y):\n",
    "    return (-torch.log(y_hat.gather(1, y.view(-1,1)))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation 函数\n",
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim = 1, keepdim = True) == y.view(-1,1)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 函数\n",
    "def network(x, w, b):\n",
    "    return softmax_fn(torch.mm(x.view(-1, w.shape[0]), w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正确率评估\n",
    "def evaluate_accuracy(data_iter, model, params = None):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    if params is not None:\n",
    "        for X, y in data_iter:\n",
    "            acc_sum += (model(X, *params).argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    else:   \n",
    "        for X, y in data_iter:\n",
    "            acc_sum += (model(X).argmax(dim=1) ==y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr*param.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch3(n_epoch, batch_size, train_iter, test_iter, model, loss_fn, evaluate_accuracy, params = None, lr = None, optimizer = None):\n",
    "    for epoch in range(n_epoch):\n",
    "        train_loss_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            if params is not None:\n",
    "                y_hat = model(X, *params)\n",
    "            else:\n",
    "                y_hat = model(X)\n",
    "            \n",
    "            loss = loss_fn(y_hat, y)\n",
    "            \n",
    "            #梯度清理\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            #backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            #参数更新\n",
    "            if optimizer is None:\n",
    "                sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                \n",
    "            #train_loss, train_acc\n",
    "            train_loss_sum += loss.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim = 1, keepdim = True) == y.view(-1,1)).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "            \n",
    "        if epoch%5 ==0:\n",
    "            if params is not None:\n",
    "                test_acc = evaluate_accuracy(test_iter, model, params)\n",
    "            else:\n",
    "                test_acc = evaluate_accuracy(test_iter, model)\n",
    "            train_acc = train_acc_sum/n\n",
    "            train_loss = train_loss_sum/n\n",
    "            print('epoch: %d, train_loss: %.4f, train_acc: %.2f, test_acc: %.2f'%(epoch, train_loss, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.0045, train_acc: 0.68, test_acc: 0.69\n",
      "epoch: 5, train_loss: 0.0026, train_acc: 0.79, test_acc: 0.78\n",
      "epoch: 10, train_loss: 0.0023, train_acc: 0.81, test_acc: 0.80\n",
      "epoch: 15, train_loss: 0.0022, train_acc: 0.82, test_acc: 0.81\n",
      "epoch: 20, train_loss: 0.0021, train_acc: 0.83, test_acc: 0.81\n",
      "epoch: 25, train_loss: 0.0020, train_acc: 0.83, test_acc: 0.82\n"
     ]
    }
   ],
   "source": [
    "train_ch3(n_epoch = 30, batch_size = 256, train_iter =train_iter, test_iter = test_iter, \n",
    "          model = network, loss_fn = cross_entropy, evaluate_accuracy = evaluate_accuracy, \n",
    "          params = [w, b], lr = 1e-2, optimizer = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x.view(x.shape[0], -1))\n",
    "        return y\n",
    "\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0],-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LinearNet(num_inputs, num_outputs)\n",
    "#network = nn.Sequential(OrderedDict([('flatten', FlattenLayer()), ('linear', nn.Linear(num_inputs, num_outputs))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.normal_(network.linear.weight, mean = 0, std = 0.01)\n",
    "init.constant_(network.linear.bias, val = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(network.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.0054, train_acc: 0.64, test_loss: 0.68\n",
      "epoch: 5, train_loss: 0.0026, train_acc: 0.79, test_loss: 0.78\n",
      "epoch: 10, train_loss: 0.0023, train_acc: 0.81, test_loss: 0.80\n",
      "epoch: 15, train_loss: 0.0022, train_acc: 0.82, test_loss: 0.81\n"
     ]
    }
   ],
   "source": [
    "train_ch3(n_epoch = 20, batch_size = 256, \n",
    "          train_iter = train_iter, test_iter = test_iter, \n",
    "          model = network, loss_fn = loss_fn, evaluate_accuracy = evaluate_accuracy, \n",
    "          params = None, lr = None, optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    t_p = w*t_u + b\n",
    "    return t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        loss = loss_fn(model(t_u, *params), t_c)\n",
    "        loss.backward()\n",
    "        params = (params - learning_rate*params.grad).detach().requires_grad_()  \n",
    "        if epoch%50 == 0:\n",
    "            print('Epoch %d, Loss %f'% (epoch, loss.float()))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
