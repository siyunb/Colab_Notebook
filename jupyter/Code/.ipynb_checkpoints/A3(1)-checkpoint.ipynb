{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Qm_mp4AmT5-t"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c93ce16b3467>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'records.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' on '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' on '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#1.1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "headers={'User-Agent':'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Mobile Safari/537.36 Edg/89.0.774.75'}\n",
    "\n",
    "url = 'https://www.google.com/search?q=america+coronavirus&rlz=1C5CHFA_enHK924&oq=america+co&aqs=chrome.1.69i57j0i457j46j0j46i175i199j0l2j69i60.20181j0j7&sourceid=chrome&ie=UTF-8#wptab=s:H4sIAAAAAAAAAONgVuLVT9c3NMwySk6OL8zJecTYxMgt8PLHPWGpyklrTl5jLOYS901NyUzOzEt1ySxOTSxO9clPTizJzM8T0uNic80rySypFFLhEpRCNUeDQYqfC1VISIOLA65XhotXilM_V9_AMtm83ACompsLweXZxcSRX5ZaVJaZWr6IVTgxN7UoMzlRITm_KD8vsSyzqLQYAJcNxFW4AAAA'\n",
    "page_text = requests.get(url=url,headers=headers)\n",
    "content = page_text.text\n",
    "soup = BeautifulSoup(content,'lxml')\n",
    "data = soup.find_all('li',text=re.compile('[0-9]+'))\n",
    "\n",
    "records=[]\n",
    "for x in data:\n",
    "    records.append(x.text.strip())\n",
    "\n",
    "f = open('records.txt', 'w', encoding = 'utf-8')\n",
    "for x in records:\n",
    "    f.write(x.split(' on ')[0]+' '+x.split(' on ')[1]+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnBMAcDZXH7k"
   },
   "outputs": [],
   "source": [
    "#1.2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('records.txt', delim_whitespace=True, names=('num', 'date'))\n",
    "for x in range(len(df)):\n",
    "    df.iloc[x]['date']='2020'+'-'+df.iloc[x]['date'].split(\"月\")[0]+'-'+ df.iloc[x]['date'].split(\"月\")[1].split(\"日\")[0]\n",
    "df=df[0:(df['date'].tolist().index('2020-10-31')+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Du0P0JLcV1Jm",
    "outputId": "da3abac2-303e-42f1-daea-86fb7d61f4c4"
   },
   "outputs": [],
   "source": [
    "df[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tketk7YFhz4d",
    "outputId": "edf255f0-65b8-4b6e-c9fd-8b3d73e9475c"
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.date)\n",
    "df=df.set_index('date')\n",
    "new_num=[]\n",
    "for x in df['num']:\n",
    "    new_num.append(int(x.replace(',', '')))\n",
    "df['num']= new_num\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Z7C0ZVHqhz4e",
    "outputId": "90615625-0553-4dfa-d414-6fb3aae5e226"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5d71226a83fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'num'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#1.3\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df.plot()\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('num')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "-b2TXqnIhz4e",
    "outputId": "84af4aac-c035-4e01-b0f0-c66a3412636f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             tweets\n",
       "0  positive  #FollowFriday @France_Inte @PKuchly57 @Milipol...\n",
       "1  positive  @Lamb2ja Hey James! How odd :/ Please call our...\n",
       "2  positive  @DespiteOfficial we had a listen last night :)...\n",
       "3  positive                               @97sides CONGRATS :)\n",
       "4  positive  yeaaaah yippppy!!!  my accnt verified rqst has..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.1\n",
    "import pandas as pd\n",
    "tweets_df = pd.read_csv('tweets.csv',encoding = 'gb18030')\n",
    "tweets_df = tweets_df.dropna()\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6GVQWjGhz4f",
    "outputId": "b6982e0a-8bf8-41d7-c099-bbb87d93e1bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4082.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#2.1\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "stopwords = stopwords.words(\"english\")\n",
    "\n",
    "def f(tweet):\n",
    "    # remove the urls\n",
    "    tweet = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                           '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', tweet)\n",
    "    # remove the @ and references\n",
    "    tweet = re.sub(r\"(@[A-Za-z0-9_]+)\",\"\", tweet)\n",
    "    # lower case\n",
    "    tweet = tweet.lower()\n",
    "    # remove  charaecters\n",
    "    tweet = re.sub(r'[\\#\\:\\)\\n\\/\\_\\-\\&]','', tweet)\n",
    "    # tokenize the words\n",
    "    word_list = word_tokenize(tweet)\n",
    "    word_list = [w for w in word_list if (not w in stopwords) and (w.isalpha())]\n",
    "    # stemming\n",
    "    porter = PorterStemmer()\n",
    "    word_list = [porter.stem(w) for w in word_list]\n",
    "    # lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = [lemmatizer.lemmatize(w, pos='a') for w in word_list]\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "processed_tweets = []\n",
    "for i in tqdm(range(tweets_df.shape[0])):\n",
    "    processed_tweets.append(f(tweets_df.iloc[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izj0o9dAhz4f",
    "outputId": "4704e905-c652-4a36-a766-c405acd90e09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['followfriday top engag member commun week',\n",
       " 'hey jame odd pleas call contact centr abl assist mani thank',\n",
       " 'listen last night bleed amaz track scotland',\n",
       " 'congrat',\n",
       " 'yeaaaah yippppi accnt verifi rqst succeed got blue tick mark fb profil day']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.1\n",
    "processed_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqPvWicFhz4g",
    "outputId": "89b68934-b767-46a5-aeec-b61144cc7674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9390)\n"
     ]
    }
   ],
   "source": [
    "#2.2\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(processed_tweets)\n",
    "print(x.shape)\n",
    "y = np.array([1 if s=='positive' else 0 for s in tweets_df.sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cE100xahz4g",
    "outputId": "4aa22d1b-1b33-4b2a-d634-97ad37346097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy for train set is 0.875375\n",
      "the accuracy for test set is 0.7495\n"
     ]
    }
   ],
   "source": [
    "#2.3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2020)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "yhat_train = clf.predict(x_train)\n",
    "yhat_test = clf.predict(x_test)\n",
    "print('the accuracy for train set is '+ str(accuracy_score(y_train,yhat_train)))\n",
    "print('the accuracy for test set is '+ str(accuracy_score(y_test,yhat_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iwD47Ks5hz4g"
   },
   "outputs": [],
   "source": [
    "#2.4\n",
    "from facebook_scraper import get_posts\n",
    "list_JB=[]\n",
    "for post in get_posts('JoeBiden',pages=5,extra_info=True):\n",
    "    list_JB.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PLaYgsN1ngkq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The American Jobs Plan is the largest American jobs investment since World War II.',\n",
       " 'More than 35% of rural America lacks access to high-speed internet.\\n\\nThe American Jobs Plan will make it easier for families who don’t have affordable service to get it and drive down internet prices for folks across our country.',\n",
       " 'The American Jobs Plan is a once-in-a-generation investment in America. It will:\\n✅Modernize 20,000 miles of highways, roads, and main streets\\n✅Repair 10,000 bridges desperately in need of upgrades\\n✅Replace 100% of our nation’s lead pipes and service lines',\n",
       " 'Millions of Americans lost their jobs last year.\\n\\nHere’s the truth: We all do better when we all do well. It’s time to build our economy from the bottom up—and the middle out—not the top down.',\n",
       " 'It matters whether you continue to wear a mask.\\nIt matters whether you continue to socially distance.\\nIt matters whether you wash your hands.\\n\\nIt all matters and can help save lives.',\n",
       " 'The American Rescue Plan means a $7,000 check for a single mom of four. It means more support to safely and quickly reopen schools. It means setting up additional vaccination sites to help America get back to normal.\\n\\nWhat does the American Rescue Plan mean to you?',\n",
       " '85% of American households will get direct checks from the American Rescue Plan.\\n\\nFor so many Americans, that means they can pay the rent. That means they can put food on the table.\\n\\nShare below what the American Rescue Plan will do for you.',\n",
       " 'A campaign for everyone who’s been knocked down or counted out.\\n\\nA campaign that brought Americans together of every race, ethnicity, gender, economic station, and party.\\n\\nA year ago, the people of South Carolina lifted that campaign on their shoulders.',\n",
       " 'Today, we begin anew. Tune in for #Inauguration2021.',\n",
       " 'Now the real work begins, folks. Follow along at President Joe Biden as we build back better.',\n",
       " 'I love you, Jilly, and I couldn’t be more grateful to have you with me on the journey ahead.',\n",
       " 'Today, we begin anew. Tune in for #Inauguration2021.',\n",
       " 'It’s a new day in America.',\n",
       " 'Tonight, in Washington, D.C. and across the nation, we came together to honor the over 400,000 Americans we’ve lost to COVID-19. The last year has tested us in unimaginable ways, but now it’s time we begin to heal and overcome — together.',\n",
       " 'We don’t have a second to waste when it comes to tackling the crises we face as a nation. That’s why after being sworn in tomorrow, I’ll get right to work.',\n",
       " 'Join us for a national moment of unity and remembrance in honor of the 400,000 Americans we’ve lost due to COVID-19.',\n",
       " 'Next stop: Washington, D.C.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_list_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "NSj7roLuhz4h",
    "outputId": "e57231b3-e91a-4052-c7e2-ecd84458c98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "proba:0.3462226001016819\n",
      "post:Next stop: Washington, D.C.\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "proba:0.4602303443842075\n",
      "post:Tonight, in Washington, D.C. and across the nation, we came together to honor the over 400,000 Americans we’ve lost to COVID-19. The last year has tested us in unimaginable ways, but now it’s time we begin to heal and overcome — together.\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "proba:0.47197513945661196\n",
      "post:The American Rescue Plan means a $7,000 check for a single mom of four. It means more support to safely and quickly reopen schools. It means setting up additional vaccination sites to help America get back to normal.\n",
      "\n",
      "What does the American Rescue Plan mean to you?\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#2.4\n",
    "post_list = [f(x['post_text']) for x in list_JB if f(x['post_text']) != '']\n",
    "x = v.transform(post_list)\n",
    "\n",
    "prob = clf.predict_proba(x)[:,1]\n",
    "\n",
    "top3=np.argsort(prob)[:3]\n",
    "\n",
    "post_list_original = [post['post_text'] for post in list_JB if f(post['post_text']) != '']\n",
    "\n",
    "for x in range(3):\n",
    "    print('------------------------------------')\n",
    "    print(\"proba:\"+str(prob[top3[x]]))\n",
    "    print('post:'+post_list_original[top3[x]])\n",
    "    print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "A3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
