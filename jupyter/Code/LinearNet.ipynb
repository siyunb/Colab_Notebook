{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unique-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as Data \n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sexual-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_figsize(figsize = (3.5, 2.5)):\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    plt.rcParams['figure.figsize'] = figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ultimate-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = 2\n",
    "num_sample = 1000\n",
    "b = torch.tensor(4.2)\n",
    "w = torch.tensor([[2], [-3.4]], dtype = torch.float)\n",
    "x = torch.randn(num_sample, num_feature, dtype = torch.float)\n",
    "e = torch.tensor(np.random.normal(0,0.01, size = (num_sample,1)), dtype = torch.float)\n",
    "y = torch.mm(x, w) + b +e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overall-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "dataset = Data.TensorDataset(x, y)\n",
    "data_iter = Data.DataLoader(dataset, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opened-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, feature):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature, 1)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y \n",
    "    \n",
    "network = LinearNet(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "simple-mother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.normal_(network.linear.weight, mean = 0, std = 0.01)\n",
    "init.constant_(network.linear.bias, val = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "convertible-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "upper-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(network.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "changing-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epoch, data_iter, x, y, model, loss_fn, optimizer):\n",
    "    for epoch in range(n_epoch):\n",
    "        for train_x, train_y in data_iter:\n",
    "            y_hat = model(train_x)\n",
    "            loss = loss_fn(y_hat, train_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch%50 == 0:\n",
    "            train_loss = loss_fn(model(x), y)\n",
    "            print('epoch: %d, train_loss: %.2f'%(epoch, train_loss))\n",
    "    for name, params in model.named_parameters():\n",
    "        print(name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "coastal-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.54\n",
      "epoch: 50, train_loss: 0.00\n",
      "epoch: 100, train_loss: 0.00\n",
      "epoch: 150, train_loss: 0.00\n",
      "epoch: 200, train_loss: 0.00\n",
      "epoch: 250, train_loss: 0.00\n",
      "epoch: 300, train_loss: 0.00\n",
      "epoch: 350, train_loss: 0.00\n",
      "epoch: 400, train_loss: 0.00\n",
      "epoch: 450, train_loss: 0.00\n",
      "linear.weight Parameter containing:\n",
      "tensor([[ 2.0006, -3.3992]], requires_grad=True)\n",
      "linear.bias Parameter containing:\n",
      "tensor([4.2003], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epoch = 500, data_iter = data_iter, \n",
    "              x = x, y = y, \n",
    "              model = network, loss_fn = loss_fn, optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-gentleman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "digital-makeup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "id_before = id(y)\n",
    "torch.add(x, y, out = y)\n",
    "print(id(y) == id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fluid-filter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3], device='cuda:0')\n",
      "tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "gpu_device = torch.device('cuda')\n",
    "cpu_device = torch.device('cpu')\n",
    "y = torch.ones_like(x, device = gpu_device)\n",
    "x = x.to(gpu_device)\n",
    "z = x + y\n",
    "print(z)\n",
    "print(z.to(cpu_device, torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "minus-harassment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 0.2000, 0.0200, 0.0020])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4], dtype = torch.float, requires_grad = True)\n",
    "y = 2*x\n",
    "z = y.view(2,2)\n",
    "v = torch.tensor([[1, 0.1],[0.01, 0.001]], dtype = torch.float)\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "academic-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_figsize(figsize = (3.5, 2.5)):\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    plt.rcParams['figure.figsize'] = figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "encouraging-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, x, y):\n",
    "    num_example = x.shape[0]\n",
    "    indices = torch.randperm(num_example)\n",
    "    for i in range(0, num_example, batch_size):\n",
    "        j = torch.LongTensor(indices[i:min(i+batch_size,num_example)])\n",
    "        yield x.index_select(0,j), y.index_select(0,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "concerned-waterproof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "False\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1, requires_grad = True)\n",
    "print(x.data)\n",
    "print(x.data.requires_grad)\n",
    "\n",
    "y = x**2\n",
    "\n",
    "x.data *= 100\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rough-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0] #known data\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] #unknown data\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extraordinary-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eight-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None: \n",
    "            params.grad.zero_() # 这可以在调用backward之前在循环中的任何时候完成\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "        params = (params - learning_rate * params.grad).detach().requires_grad_()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "medieval-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860115\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957698\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_un = 0.1 * t_u\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-2,\n",
    "    params = torch.tensor([1.0, 0.0], requires_grad=True),\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "likely-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "powered-steel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0965, -0.0165], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "excited-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    optimizer = optim.SGD([params], lr = learning_rate)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None: \n",
    "            params.grad.zero_() # 这可以在调用backward之前在循环中的任何时候完成\n",
    "        loss = loss_fn(model(t_u, *params), t_c)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "material-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = loss_fn(model(t_u, *params), t_c)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "coated-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "supreme-nature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860115\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957698\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_un = 0.1 * t_u\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_un,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "unusual-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "agricultural-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.612900\n",
      "Epoch 1000, Loss 3.086700\n",
      "Epoch 1500, Loss 2.928579\n",
      "Epoch 2000, Loss 2.927644\n",
      "Epoch 2500, Loss 2.927645\n",
      "Epoch 3000, Loss 2.927646\n",
      "Epoch 3500, Loss 2.927645\n",
      "Epoch 4000, Loss 2.927646\n",
      "Epoch 4500, Loss 2.927646\n",
      "Epoch 5000, Loss 2.927645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.5368, -17.3048], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_u,\n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "preceding-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "induced-contrast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 5, 3, 1, 2, 8, 7, 0, 9]), tensor([10,  4]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2*n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "steady-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices] \n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "train_t_un = train_t_u*0.1\n",
    "val_t_un = val_t_u*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "equipped-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch %d, Training Loss %.2f, Validation Loss %.2f' % (epoch, train_loss.float(), val_loss.float()))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "processed-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "mature-atlas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Training Loss 32.35, Validation Loss 14.88\n",
      "Epoch 100, Training Loss 26.35, Validation Loss 11.49\n",
      "Epoch 150, Training Loss 19.50, Validation Loss 9.84\n",
      "Epoch 200, Training Loss 13.95, Validation Loss 8.28\n",
      "Epoch 250, Training Loss 9.78, Validation Loss 6.98\n",
      "Epoch 300, Training Loss 6.88, Validation Loss 5.92\n",
      "Epoch 350, Training Loss 5.00, Validation Loss 5.08\n",
      "Epoch 400, Training Loss 3.88, Validation Loss 4.44\n",
      "Epoch 450, Training Loss 3.27, Validation Loss 3.96\n",
      "Epoch 500, Training Loss 2.99, Validation Loss 3.60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.1335, -15.9296], requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=500, optimizer = optimizer, params = params, \n",
    "              train_t_u = train_t_u, train_t_c = train_t_c, val_t_u = val_t_u, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dated-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_t_p = model(val_t_u, *params)\n",
    "            val_loss = loss_fn(val_t_p, val_t_c)\n",
    "            assert val_loss.requires_grad == False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch %d, Training Loss %.2f, Validation Loss %.2f' % (epoch, train_loss.float(), val_loss.float()))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "abandoned-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "split-degree",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Training Loss 27.32, Validation Loss 17.74\n",
      "Epoch 100, Training Loss 17.60, Validation Loss 12.63\n",
      "Epoch 150, Training Loss 10.88, Validation Loss 9.16\n",
      "Epoch 200, Training Loss 6.83, Validation Loss 6.84\n",
      "Epoch 250, Training Loss 4.66, Validation Loss 5.36\n",
      "Epoch 300, Training Loss 3.61, Validation Loss 4.46\n",
      "Epoch 350, Training Loss 3.15, Validation Loss 3.92\n",
      "Epoch 400, Training Loss 2.97, Validation Loss 3.61\n",
      "Epoch 450, Training Loss 2.90, Validation Loss 3.43\n",
      "Epoch 500, Training Loss 2.88, Validation Loss 3.34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.2488, -16.6556], requires_grad=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=500, optimizer = optimizer, params = params, \n",
    "              train_t_u = train_t_u, train_t_c = train_t_c, \n",
    "              val_t_u = val_t_u, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "binary-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    t_p = w_2*t_u*t_u + w_1*t_u + b\n",
    "    return t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "other-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clalc_forward(t_u, t_c, params,is_train):\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "amino-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = clalc_forward(train_t_u, train_t_c, params, is_train = True)\n",
    "        val_loss = clalc_forward(val_t_u, val_t_c, params, is_train = False)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch %d, Training Loss %.2f, Validation Loss %.2f' % (epoch, train_loss.float(), val_loss.float()))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "worth-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "verbal-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Training Loss 7.06, Validation Loss 6.64\n",
      "Epoch 100, Training Loss 4.39, Validation Loss 3.14\n",
      "Epoch 150, Training Loss 3.49, Validation Loss 2.44\n",
      "Epoch 200, Training Loss 3.25, Validation Loss 2.10\n",
      "Epoch 250, Training Loss 3.18, Validation Loss 1.96\n",
      "Epoch 300, Training Loss 3.14, Validation Loss 1.91\n",
      "Epoch 350, Training Loss 3.10, Validation Loss 1.90\n",
      "Epoch 400, Training Loss 3.06, Validation Loss 1.89\n",
      "Epoch 450, Training Loss 3.01, Validation Loss 1.89\n",
      "Epoch 500, Training Loss 2.97, Validation Loss 1.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5050, -0.0422, -4.1968], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs=500, optimizer = optimizer, params = params, \n",
    "              train_t_u = train_t_u, train_t_c = train_t_c, \n",
    "              val_t_u = val_t_u, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "amazing-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0] #known data\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] #unknown data\n",
    "t_u = torch.tensor(t_u)\n",
    "t_c = torch.tensor(t_c)\n",
    "\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2*n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "train_indices, val_indices\n",
    "\n",
    "train_t_u = t_u[train_indices].unsqueeze(1)\n",
    "train_t_c = t_c[train_indices].unsqueeze(1)\n",
    "val_t_u = t_u[val_indices].unsqueeze(1)\n",
    "val_t_c = t_c[val_indices].unsqueeze(1)\n",
    "\n",
    "train_t_un = train_t_u*0.1 \n",
    "val_t_un = val_t_u*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wicked-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(1,1)\n",
    "optimizer = optim.Adam(linear_model.parameters(),lr = 1e-2)\n",
    "loss_fn = torch.nn.MSELoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "phantom-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epoch, model, loss_fn, optimizer, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(1,n_epoch+1):\n",
    "        train_t_p = model(train_t_u)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch%500 ==0:\n",
    "            print('Epoch: %d, Train_Loss: %.2f, Val_Loss: %.2f'%(epoch, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "demanding-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Train_Loss: 4.42, Val_Loss: 10.54\n",
      "Epoch: 1000, Train_Loss: 4.11, Val_Loss: 9.39\n",
      "Epoch: 1500, Train_Loss: 3.81, Val_Loss: 8.25\n",
      "Epoch: 2000, Train_Loss: 3.52, Val_Loss: 7.12\n",
      "Epoch: 2500, Train_Loss: 3.28, Val_Loss: 6.08\n",
      "Epoch: 3000, Train_Loss: 3.09, Val_Loss: 5.20\n",
      "Epoch: 3500, Train_Loss: 2.96, Val_Loss: 4.52\n",
      "Epoch: 4000, Train_Loss: 2.89, Val_Loss: 4.05\n",
      "Epoch: 4500, Train_Loss: 2.86, Val_Loss: 3.75\n",
      "Epoch: 5000, Train_Loss: 2.85, Val_Loss: 3.59\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epoch = 5000, model = linear_model, loss_fn = loss_fn, optimizer = optimizer, \n",
    "              train_t_u = train_t_un, train_t_c = train_t_c, val_t_u = val_t_un, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "conditional-dublin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[5.2194]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-16.5031], requires_grad=True)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "extensive-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = nn.Sequential(\n",
    "            nn.Linear(1,13),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(13,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "terminal-alpha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.7766],\n",
       "         [ 0.6892],\n",
       "         [-0.8019],\n",
       "         [-0.6600],\n",
       "         [ 0.6577],\n",
       "         [-0.6652],\n",
       "         [ 0.3134],\n",
       "         [ 0.0567],\n",
       "         [-0.9726],\n",
       "         [-0.0121],\n",
       "         [-0.4719],\n",
       "         [-0.7999],\n",
       "         [ 0.9525]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.5310,  0.4305, -0.0568,  0.7060,  0.3968, -0.6428, -0.0676,  0.6612,\n",
       "         -0.4612,  0.0518, -0.0779, -0.5959,  0.6725], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1151, -0.0934, -0.2451, -0.1570, -0.0616,  0.2053,  0.0405, -0.0290,\n",
       "           0.0036,  0.1307,  0.1540, -0.0044,  0.0348]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0443], requires_grad=True)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param for param in seq_model.parameters()]# 线性层的权重和偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "handled-shadow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([13, 1])\n",
      "0.bias torch.Size([13])\n",
      "2.weight torch.Size([1, 13])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "likely-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "structured-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(1,8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8,1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "juvenile-variation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 1])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "advance-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq_model.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "disciplinary-mauritius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Train_Loss: 60.61, Val_Loss: 300.73\n",
      "Epoch: 1000, Train_Loss: 32.88, Val_Loss: 209.32\n",
      "Epoch: 1500, Train_Loss: 18.16, Val_Loss: 150.69\n",
      "Epoch: 2000, Train_Loss: 11.69, Val_Loss: 114.63\n",
      "Epoch: 2500, Train_Loss: 8.10, Val_Loss: 89.95\n",
      "Epoch: 3000, Train_Loss: 5.63, Val_Loss: 70.97\n",
      "Epoch: 3500, Train_Loss: 3.96, Val_Loss: 56.26\n",
      "Epoch: 4000, Train_Loss: 2.77, Val_Loss: 44.85\n",
      "Epoch: 4500, Train_Loss: 1.99, Val_Loss: 36.39\n",
      "Epoch: 5000, Train_Loss: 1.58, Val_Loss: 30.52\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epoch = 5000, model = seq_model, loss_fn = loss_fn, optimizer = optimizer, \n",
    "              train_t_u = train_t_un, train_t_c = train_t_c, val_t_u = val_t_un, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "industrial-canal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([[22.8139],\n",
      "        [16.3079]], grad_fn=<AddmmBackward>)\n",
      "answer tensor([[28.],\n",
      "        [13.]])\n",
      "hidden tensor([[-0.0002],\n",
      "        [-0.0032],\n",
      "        [-0.0003],\n",
      "        [-0.0019],\n",
      "        [ 0.0007],\n",
      "        [-0.0020],\n",
      "        [ 0.0002],\n",
      "        [ 0.0020]])\n"
     ]
    }
   ],
   "source": [
    "print('output', seq_model(val_t_un))\n",
    "print('answer', val_t_c)\n",
    "print('hidden', seq_model.hidden_linear.weight.grad )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "substantial-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "t_range = torch.arange(20., 90.).unsqueeze(1)\n",
    "\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.xlabel(\"Fahrenheit\")\n",
    "plt.ylabel(\"Celsius\")\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
    "plt.plot(t_range.numpy(), seq_model(0.1 * t_range).detach().numpy(), 'c-')\n",
    "plt.plot(t_u.numpy(), seq_model(0.1 * t_u.unsqueeze(1)).detach().numpy(), 'kx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "chronic-crowd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=11, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=11, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = nn.Sequential(\n",
    "                          nn.Linear(1, 11),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(11,1))\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "distributed-terminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=1, out_features=11, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=11, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "                                      ('hidden_linear', nn.Linear(1, 11)),\n",
    "                                      ('hidden_activation', nn.Tanh()),\n",
    "                                      ('output_linear', nn.Linear(11, 1))\n",
    "                                      ]))\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "amber-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubclassModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_linear = nn.Linear(1, 11)\n",
    "        self.output_linear = nn.Linear(11, 1)\n",
    "    def forward(self, input):\n",
    "        hidden_t = self.hidden_linear(input)\n",
    "        activated_t = torch.tanh(hidden_t)\n",
    "        output_t = self.output_linear(activated_t)\n",
    "        return output_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "regional-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubclassModel(\n",
       "  (hidden_linear): Linear(in_features=1, out_features=11, bias=True)\n",
       "  (output_linear): Linear(in_features=11, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = SubclassModel()\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "oriented-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq_model.parameters(),lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "statistical-experience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Train_Loss: 56.56, Val_Loss: 279.17\n",
      "Epoch: 1000, Train_Loss: 29.55, Val_Loss: 182.59\n",
      "Epoch: 1500, Train_Loss: 14.65, Val_Loss: 123.20\n",
      "Epoch: 2000, Train_Loss: 8.54, Val_Loss: 88.12\n",
      "Epoch: 2500, Train_Loss: 6.04, Val_Loss: 66.98\n",
      "Epoch: 3000, Train_Loss: 4.32, Val_Loss: 51.31\n",
      "Epoch: 3500, Train_Loss: 3.24, Val_Loss: 39.41\n",
      "Epoch: 4000, Train_Loss: 2.55, Val_Loss: 30.66\n",
      "Epoch: 4500, Train_Loss: 2.09, Val_Loss: 24.14\n",
      "Epoch: 5000, Train_Loss: 1.76, Val_Loss: 19.32\n"
     ]
    }
   ],
   "source": [
    "training_loop(n_epoch = 5000, model = seq_model, loss_fn = loss_fn, optimizer = optimizer, \n",
    "              train_t_u = train_t_un, train_t_c = train_t_c, val_t_u = val_t_un, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-necklace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
