{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nilearn import datasets\r\n",
    "from nilearn.input_data import NiftiLabelsMasker\r\n",
    "from nilearn.connectome import ConnectivityMeasure\r\n",
    "from nilearn.connectome import GroupSparseCovarianceCV\r\n",
    "#在绘制透明大脑上连通性相互作用有用\r\n",
    "from nilearn import plotting\r\n",
    "from nilearn import input_data\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yeo = datasets.fetch_atlas_yeo_2011()\r\n",
    "print('Yeo atlas nifti image (3D) with 17 parcels and liberal mask is located '\r\n",
    "      'at: %s' % yeo['thick_17'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = datasets.fetch_development_fmri(n_subjects=10)\r\n",
    "print('Functional nifti images (4D, e.g., one subject) are located at : %r'\r\n",
    "      % data['func'][0])\r\n",
    "print('Counfound csv files (of same subject) are located at : %r'\r\n",
    "      % data['confounds'][0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nilearn的ConenctivityMeasure使用简单的“相关性”来计算列表中所有主题的连通性矩阵\r\n",
    "connectome_measure = ConnectivityMeasure(kind='correlation')\r\n",
    "\r\n",
    "# 创建遮罩程序以提取地图集中的功能数据\r\n",
    "masker = NiftiLabelsMasker(labels_img=yeo['thick_17'], standardize=True,\r\n",
    "                           memory='nilearn_cache')\r\n",
    "\r\n",
    "# 从所有主题中提取时间序列并将它们串联\r\n",
    "time_series = []\r\n",
    "for func, confounds in zip(data.func, data.confounds):\r\n",
    "    time_series.append(masker.fit_transform(func, confounds=confounds))\r\n",
    "\r\n",
    "# 计算跨主题的相关矩阵并显示\r\n",
    "correlation_matrices = connectome_measure.fit_transform(time_series)\r\n",
    "\r\n",
    "# 使用连接套测量对象，可以像这样获取10个对象的平均相关矩阵\r\n",
    "mean_correlation_matrix = connectome_measure.mean_\r\n",
    "\r\n",
    "# 获取地图集标签的中心坐标\r\n",
    "coordinates = plotting.find_parcellation_cut_coords(labels_img=yeo['thick_17'])\r\n",
    "\r\n",
    "# 在连接中以80％的边缘强度绘制连接图\r\n",
    "plotting.plot_connectome(mean_correlation_matrix, coordinates,\r\n",
    "                         edge_threshold=\"80%\",\r\n",
    "                         title='Yeo Atlas 17 thick (func)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "msdl = datasets.fetch_atlas_msdl()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 创建遮罩程序以提取地图集中的功能数据\r\n",
    "masker = NiftiMapsMasker(maps_img=msdl['maps'], standardize=True,\r\n",
    "                         memory='nilearn_cache')\r\n",
    "\r\n",
    "# 从所有主题中提取时间序列并将它们串联\r\n",
    "time_series = []\r\n",
    "for func, confounds in zip(data.func, data.confounds):\r\n",
    "    time_series.append(masker.fit_transform(func, confounds=confounds))\r\n",
    "\r\n",
    "# 计算跨主题的相关矩阵并显示\r\n",
    "correlation_matrices = connectome_measure.fit_transform(time_series)\r\n",
    "\r\n",
    "# 使用连接套测量对象，可以像这样获取10个对象的平均相关矩阵\r\n",
    "mean_correlation_matrix = connectome_measure.mean_\r\n",
    "\r\n",
    "# grab center coordinates for probabilistic atlas\r\n",
    "coordinates = plotting.find_probabilistic_atlas_cut_coords(maps_img=msdl['maps'])\r\n",
    "\r\n",
    "# 在连接中以80％的边缘强度绘制连接图\r\n",
    "plotting.plot_connectome(mean_correlation_matrix, coordinates,\r\n",
    "                         edge_threshold=\"80%\", title='MSDL (probabilistic)')\r\n",
    "plotting.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 我们将研究大脑发育fmri数据集的第一个主题。\r\n",
    "# dataset.func是文件名列表。 \r\n",
    "# 我们通过使用[0]进行索引来选择第一个（基于0的）主题。\r\n",
    "\r\n",
    "dataset = datasets.fetch_development_fmri(n_subjects=1)\r\n",
    "func_filename = dataset.func[0]\r\n",
    "confound_filename = dataset.confounds[0]\r\n",
    "\r\n",
    "print(funcfilename)\r\n",
    "print(confound_filename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pcc_coords = [(0, -52, 18)]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seed_masker = input_data.NiftiSpheresMasker(\r\n",
    "    pcc_coords, radius=8,\r\n",
    "    detrend=True, standardize=True,\r\n",
    "    low_pass=0.1, high_pass=0.01, t_r=2,\r\n",
    "    memory='nilearn_cache', memory_level=1, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seed_time_series = seed_masker.fit_transform(func_filename,\r\n",
    "                                             confounds=[confound_filename])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "brain_masker = input_data.NiftiMasker(\r\n",
    "    smoothing_fwhm=6,\r\n",
    "    detrend=True, standardize=True,\r\n",
    "    low_pass=0.1, high_pass=0.01, t_r=2,\r\n",
    "    memory='nilearn_cache', memory_level=1, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "brain_time_series = brain_masker.fit_transform(func_filename,\r\n",
    "                                               confounds=[confound_filename])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Seed time series shape: (%s, %s)\" % seed_time_series.shape)\r\n",
    "print(\"Brain time series shape: (%s, %s)\" % brain_time_series.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(seed_time_series)\r\n",
    "plt.title('Seed time series (Posterior cingulate cortex)')\r\n",
    "plt.xlabel('Scan number')\r\n",
    "plt.ylabel('Normalized signal')\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(brain_time_series[:, [10, 45, 100, 5000, 10000]])\r\n",
    "plt.title('Time series from 5 random voxels')\r\n",
    "plt.xlabel('Scan number')\r\n",
    "plt.ylabel('Normalized signal')\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seed_to_voxel_correlations = (np.dot(brain_time_series.T, seed_time_series) /\r\n",
    "                              seed_time_series.shape[0]\r\n",
    "                              )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Seed-to-voxel correlation shape: (%s, %s)\" %\r\n",
    "      seed_to_voxel_correlations.shape)\r\n",
    "print(\"Seed-to-voxel correlation: min = %.3f; max = %.3f\" % (\r\n",
    "    seed_to_voxel_correlations.min(), seed_to_voxel_correlations.max()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seed_to_voxel_correlations_img = brain_masker.inverse_transform(\r\n",
    "    seed_to_voxel_correlations.T)\r\n",
    "display = plotting.plot_stat_map(seed_to_voxel_correlations_img,\r\n",
    "                                 threshold=0.5, vmax=1,\r\n",
    "                                 cut_coords=pcc_coords[0],\r\n",
    "                                 title=\"Seed-to-voxel correlation (PCC seed)\"\r\n",
    "                                 )\r\n",
    "display.add_markers(marker_coords=pcc_coords, marker_color='g',\r\n",
    "                    marker_size=300)\r\n",
    "# At last, we save the plot as pdf.\r\n",
    "display.savefig('pcc_seed_correlation.pdf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seed_to_voxel_correlations_fisher_z = np.arctanh(seed_to_voxel_correlations)\r\n",
    "print(\"Seed-to-voxel correlation Fisher-z transformed: min = %.3f; max = %.3f\"\r\n",
    "      % (seed_to_voxel_correlations_fisher_z.min(),\r\n",
    "         seed_to_voxel_correlations_fisher_z.max()\r\n",
    "         )\r\n",
    "      )\r\n",
    "# 最后，我们可以将相关性数组转换回我们可以保存的Nifti图像对象\r\n",
    "seed_to_voxel_correlations_fisher_z_img = brain_masker.inverse_transform(\r\n",
    "    seed_to_voxel_correlations_fisher_z.T)\r\n",
    "seed_to_voxel_correlations_fisher_z_img.to_filename(\r\n",
    "    'pcc_seed_correlation_z.nii.gz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_subjects = 4  # 组稀疏协方差考虑的主题（最多40个）\r\n",
    "def plot_matrices(cov, prec, title, labels):\r\n",
    "    \"\"\"Plot covariance and precision matrices, for a given processing. \"\"\"\r\n",
    "\r\n",
    "    prec = prec.copy()  # 避免副作用\r\n",
    "\r\n",
    "    # 为了使图清晰，请在对角线上放置零。\r\n",
    "    size = prec.shape[0]\r\n",
    "    prec[list(range(size)), list(range(size))] = 0\r\n",
    "    span = max(abs(prec.min()), abs(prec.max()))\r\n",
    "    # 显示协方差矩阵\r\n",
    "    plotting.plot_matrix(cov, cmap=plotting.cm.bwr,\r\n",
    "                         vmin=-1, vmax=1, title=\"%s / covariance\" % title,\r\n",
    "                         labels=labels)\r\n",
    "    # 显示精度矩阵\r\n",
    "    plotting.plot_matrix(prec, cmap=plotting.cm.bwr,\r\n",
    "                         vmin=-span, vmax=span, title=\"%s / precision\" % title,\r\n",
    "                         labels=labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "msdl_atlas_dataset = datasets.fetch_atlas_msdl()\r\n",
    "rest_dataset = datasets.fetch_development_fmri(n_subjects=n_subjects)\r\n",
    "\r\n",
    "# 在数据集上打印基本信息\r\n",
    "print('First subject functional nifti image (4D) is at: %s' %\r\n",
    "      rest_dataset.func[0])  # 4D data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from nilearn._utils.compat import Memory\r\n",
    "mem = Memory('nilearn_cache')\r\n",
    "masker = input_data.NiftiMapsMasker(\r\n",
    "    msdl_atlas_dataset.maps, resampling_target=\"maps\", detrend=True,\r\n",
    "    low_pass=None, high_pass=0.01, t_r=2, standardize=True,\r\n",
    "    memory='nilearn_cache', memory_level=1, verbose=2)\r\n",
    "masker.fit()\r\n",
    "subject_time_series = []\r\n",
    "func_filenames = rest_dataset.func\r\n",
    "confound_filenames = rest_dataset.confounds\r\n",
    "for func_filename, confound_filename in zip(func_filenames,\r\n",
    "                                            confound_filenames):\r\n",
    "    print(\"Processing file %s\" % func_filename)\r\n",
    "    # Computing some confounds\r\n",
    "    hv_confounds = mem.cache(image.high_variance_confounds)(\r\n",
    "        func_filename)\r\n",
    "\r\n",
    "    region_ts = masker.transform(func_filename,\r\n",
    "                                 confounds=[hv_confounds, confound_filename])\r\n",
    "    subject_time_series.append(region_ts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gsc = GroupSparseCovarianceCV(verbose=2)\r\n",
    "gsc.fit(subject_time_series)\r\n",
    "\r\n",
    "try:\r\n",
    "    from sklearn.covariance import GraphicalLassoCV\r\n",
    "except ImportError:\r\n",
    "    # for Scitkit-Learn < v0.20.0\r\n",
    "    from sklearn.covariance import GraphLassoCV as GraphicalLassoCV\r\n",
    "\r\n",
    "gl = GraphicalLassoCV(verbose=2)\r\n",
    "gl.fit(np.concatenate(subject_time_series))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "atlas_img = msdl_atlas_dataset.maps\r\n",
    "atlas_region_coords = plotting.find_probabilistic_atlas_cut_coords(atlas_img)\r\n",
    "labels = msdl_atlas_dataset.labels\r\n",
    "\r\n",
    "plotting.plot_connectome(gl.covariance_,\r\n",
    "                         atlas_region_coords, edge_threshold='90%',\r\n",
    "                         title=\"Covariance\",\r\n",
    "                         display_mode=\"lzr\")\r\n",
    "plotting.plot_connectome(-gl.precision_, atlas_region_coords,\r\n",
    "                         edge_threshold='90%',\r\n",
    "                         title=\"Sparse inverse covariance (GraphicalLasso)\",\r\n",
    "                         display_mode=\"lzr\",\r\n",
    "                         edge_vmax=.5, edge_vmin=-.5)\r\n",
    "plot_matrices(gl.covariance_, gl.precision_, \"GraphicalLasso\", labels)\r\n",
    "\r\n",
    "title = \"GroupSparseCovariance\"\r\n",
    "plotting.plot_connectome(-gsc.precisions_[..., 0],\r\n",
    "                         atlas_region_coords, edge_threshold='90%',\r\n",
    "                         title=title,\r\n",
    "                         display_mode=\"lzr\",\r\n",
    "                         edge_vmax=.5, edge_vmin=-.5)\r\n",
    "plot_matrices(gsc.covariances_[..., 0],\r\n",
    "              gsc.precisions_[..., 0], title, labels)\r\n",
    "\r\n",
    "plotting.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('mne': conda)"
  },
  "interpreter": {
   "hash": "90468533fe8d1c698846ed98af388de47385889fcc7d910c2dd0c9be3a41343a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}